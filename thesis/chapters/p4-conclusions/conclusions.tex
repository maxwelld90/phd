%!TEX TS-program = xelatex
%!TEX root = ../../maxwell2018thesis.tex

\chapter[Discussion, Conclusions and Future Work]{Discussion, Conclusions\\and Future Work}\label{chap:conclusions}
With all experimental work now reported, this final chapter provides a conclusion for this thesis. In particular, we provide a high-level summary of the thesis and the reported results, as well a discussion of the results from our simulated analyses. In particular, we emphasise the impact of these findings on~\gls{acr:ir} and~\gls{acr:iir} research. We then outline several potential future research directions, before concluding with some final remarks.

\section{Thesis Summary}\label{sec:conclusions:summary}
In this thesis, we examined how stopping behaviour varies under different search contexts. In particular, we conducted and reported on two user studies under the domain of news search, examining how:~\raisebox{-.2\height}{\includegraphics[height=5mm]{figures/ch2-point1.pdf}} result summary lengths; and~\raisebox{-.2\height}{\includegraphics[height=5mm]{figures/ch2-point2.pdf}} a variation of search tasks, goals and retrieval system affected search behaviours. Result summary interface variations considered a steady increase in the number of snippet fragments considered, all under ad-hoc, time-limited search. This yielded: interfaces \blueboxbold{T0} \emph{(title and no snippets);} \blueboxbold{T1} \emph{(title and one snippet);} \blueboxbold{T2} \emph{(title and two snippets);} and \blueboxbold{T4} \emph{(title and four snippets).} For the latter study reported in Chapter~\ref{chap:diversity}, we considered ad-hoc and aspectual retrieval search tasks (under non-diversified and diversified systems), with \emph{find $x$ relevant} and \emph{find $x$ relevant and new} search goals, without time limits. These were considered under two different systems, one returning results under our baseline BM25 implementation, with the other returning results under BM25 and XQuAD~\citep{santos2010query_reformulations_diversification}. This yielded four conditions, namely: \dualbluebox{D}{AS} \emph{(diversified system, aspectual task);} \dualbluebox{ND}{AS} \emph{(non-diversified system, aspectual task);} \dualbluebox{D}{AD} \emph{(diversified system ad-hoc task);} and \dualbluebox{ND}{AD} \emph{(non-diversified system, ad-hoc task).} Table~\ref{tbl:conclusion_cond_interface_summary} presents a summary table of the different interfaces, systems, and tasks used across the eight variations trialled.

\begin{table}[t!]
    \caption[Summary of experimental interfaces and conditions]{A summary table of the different experimental interfaces and conditions that were trialled. These are based upon the work reported in Chapters~\ref{chap:snippets} and~\ref{chap:diversity}. In total, eight different experimental interfaces and conditioned were employed, considering different result summary lengths, systems and tasks.}
    \label{tbl:conclusion_cond_interface_summary}
    \renewcommand{\arraystretch}{1.8}
    \begin{center}
    \begin{tabulary}{\textwidth}{L{0.4cm}@{\CS}L{3.2cm}@{\CS}D{3.51cm}@{\CS}D{3.51cm}@{\CS}D{3.51cm}@{\CS}}
        & & \lbluecell \textbf{Summary Length} & \lbluecell \textbf{System} & \lbluecell \textbf{Task} \\
        
        \RS \multirow{4}{*}{\rotatebox{90}{\hspace*{-4mm}\textbf{Chapter~\ref{chap:snippets}}}} & \lbluecell\textbf{T0} & \cell \small{Title only} & \cell \small{\blueboxbold{ND} (Non Div.)} & \cell \small{\darkblueboxbold{AD} (Ad-hoc)}\\
        \RS & \lbluecell\textbf{T1} & \cell \small{Title + 1 snippet} & \cell \small{\blueboxbold{ND} (Non Div.)} & \cell \small{\darkblueboxbold{AD} (Ad-hoc)}\\
        \RS & \lbluecell\textbf{T2} & \cell \small{Title + 2 snippets} & \cell \small{\blueboxbold{ND} (Non Div.)} & \cell \small{\darkblueboxbold{AD} (Ad-hoc)}\\
        \RS & \lbluecell\textbf{T4} & \cell \small{Title + 4 snippets} & \cell \small{\blueboxbold{ND} (Non Div.)} & \cell \small{\darkblueboxbold{AD} (Ad-hoc)}\\
        
        \RS\RS\RS \multirow{4}{*}{\rotatebox{90}{\hspace*{-4mm}\textbf{Chapter~\ref{chap:diversity}}}} & \lbluecell\textbf{D-AS} & \cell \small{Title + 2 snippets} & \cell \small{\blueboxbold{D} (Div.)} & \cell \small{\darkblueboxbold{AS} (Aspectual)}\\
        \RS & \lbluecell\textbf{ND-AS} & \cell \small{Title + 2 snippets} & \cell \small{\blueboxbold{ND} (Non Div.)} & \cell \small{\darkblueboxbold{AS} (Aspectual)}\\
        \RS & \lbluecell\textbf{D-AD} & \cell \small{Title + 2 snippets} & \cell \small{\blueboxbold{D} (Div.)} & \cell \small{\darkblueboxbold{AD} (Ad-hoc)}\\
        \RS & \lbluecell\textbf{ND-AD} & \cell \small{Title + 2 snippets} & \cell \small{\blueboxbold{ND} (Non Div.)} & \cell \small{\darkblueboxbold{AD} (Ad-hoc)}\\
        
    \end{tabulary}
    \end{center}
\end{table}

Results from the user studies showed that as result summary lengths increased from \blueboxbold{T0} $\rightarrow$ \blueboxbold{T4}, searchers became more confident in their decisions pertaining to the relevance of documents encountered. However, this was not empirically reflected; indeed, their accuracy in identifying relevant content did not improve with longer result summaries. In terms of stopping behaviours, a downward trend was observed -- as the length of result summaries increased, subjects examined to shallower depths per query. Considering tasks, goals and systems, we found that when using system \blueboxbold{D}, subjects issued more queries and stopped at comparatively shallower depths per query. This is in comparison to system \blueboxbold{ND}, where subjects reported feeling less confident with their decisions. Despite the significant differences we observed in how the two systems performed, we found few significant differences in terms of reported searcher behaviours.

Interaction data from these user studies were then used to ground an extensive set of simulations of interaction. These simulations were designed to test a total of twelve individual stopping strategies, derived from a variety of stopping heuristics\footnote{Stopping heuristics for example considered a searcher's tolerance to non-relevance, or their \emph{frustration} with observing non-relevant content~\citep{kraft1979stopping_rules}.} and~\gls{acr:ir} measures as defined in the literature. Their cataloguing and subsequent operationalisation into stopping strategies provided an answer to \darkblueboxbold{HL-RQ2}. Testing overall performance and how closely the simulations matched up to real-world searcher behaviours across the eight experimental interfaces and conditions, we could then provide answers to both \darkblueboxbold{HL-RQ3a} and \darkblueboxbold{HL-RQ3b}. The simulations were based upon the~\glsfirst{acr:csm}, an updated, high-level conceptual model of the search process. By incorporating a new~\gls{acr:serp} level stopping decision point into the~\gls{acr:csm}, complete with subsequent empirical evaluation (as presented in Chapter~\ref{chap:serp}), we could then provide an answer to \darkblueboxbold{HL-RQ1}.

Results show that when enabled, the new~\gls{acr:serp} stopping decision point leads to significant improvements over the baseline implementation, with consistent improvements in overall performance (measured in~\gls{acr:cg}) reported across a range of experimental conditions, interfaces and stopping strategies. In consideration of approximating real-world searcher stopping behaviours, improvements are also present -- these however were not significantly different. Overall however, these results provide compelling evidence for \darkblueboxbold{HL-RQ1}, and also demonstrate a promising direction for future research in developing our understanding of the search process.

With respect to our simulated analyses of individual stopping strategies, we found several stopping strategies offered the highest overall levels of~\gls{acr:cg} and good approximations with actual searcher stopping behaviours. For example, as result summary lengths increased, we found that \blueboxbold{SS11-COMB} consistently offered the best performance, with both \blueboxbold{SS1-FIX} and \blueboxbold{SS4-SAT} offering the best real-world searcher approximations. \blueboxbold{SS5-COMB} also offered the best overall levels of~\gls{acr:cg} across the second user study, with \blueboxbold{SS1-FIX} again offering the best levels of performance across condition \dualbluebox{ND}{AD}. In terms of approximations, \blueboxbold{SS1-FIX} and \blueboxbold{SS10-RELTIME} yielded the lowest MSE values. However, despite these strategies performing well, no one strategy clearly emerged as offering significantly improved levels of performance or approximations. However, several more complex stopping strategies such as \blueboxbold{SS6-DT} and \blueboxbold{SS7-DKL} consistently offered poorer performance and approximations. This is a common theme in our results: simplistic and combination-based stopping strategies generally performed better. This includes the fixed-depth stopping strategy, \blueboxbold{SS1-FIX}, which, counter to our intuition, consistently performed well. These results show that modelling stopping behaviours \emph{is} indeed difficult.

\section{\todo{Discussion}}\label{sec:conclusions:discussion}
so there is the summary.
however, there's a lot of questions about why we got the results that we did.
why is that so?
in this section, we discuss a number of our findings, exploring why the results are what they are.

\subsection{Improving Realism}

- discuss the new decision point.

- chapter 8 simulations...
- however, in terms of performance, the simulated searchers don't do much better on D-AS than D-AD. why?
    - probably because our decision maker didn't help much. doesn't differentiate between relevant and new and relevant.
    - future work. how we instantiate the simulations.
    - maybe this also accounts for why the stopping strategies (or some of them) appeared to underestimate the mean stopping depth. perhaps a better decision maker would be better for this.
    
- does this account for the poor levels of mean cg that are attained in Figure 8.9 compared to the CG attained in Chapter 7?
    - the real-world searchers performed generally better than all of the simulated stopping strategies.
        - what does this suggest? is there another strategy out there that better fits this kind of task?
        - only task that a stopping strategy did offer better approximations for in terms of CG is ND-AS. Which is T2. SS3 does better there. but why?

\subsection{Stopping Strategies and Behaviours}

- simple strategies always perform best.
- the more complex, the worse the performance and approximations get.
    - this could be because of the way we instantiate.
    - IFT/difference.
        - you would expect perhaps with difference, the only strategies that look at the terms, that improvements would be observable as snippet lengths increase. however, this is not the case.

- why does the IFT-based stopping heuristic do so badly? it's the rate of gain computation. our assumptions don't really work over a per-topic basis. think about it this way. consider a topic with a small number of rel documents, and a topic with a large number of rel docs. doesn't matter if it's a good query, it'll be harder to find relevant material for the more difficult topic! so the rate of gain we used doesn't work. so this will be interesting to explore in future work.

- why are the different rules so bad? However, \blueboxbold{QS13} hides the bimodal distribution of performance that would have been experienced during searching. As we examine later, we posit that this may have been detrimental to difference-based stopping strategies \blueboxbold{SS6-DT} and \blueboxbold{SS6-DKL}. This is due to the face that for single term queries, the diversity of the results was likely to be much greater than for three term queries. Consequently, for single term queries that provide little gain, the simulated searcher was likely to have examined to much greater depths.

for frustration rules, as i am more tolerant to nonrel information, i go deeper, has n effect of increased CG.
satisfaction, if i look for one, then stop, tends to be better than going deeper. but kind of surprising.
ift is pretty smooth, following the rate of gain is not the best. maybe it is how we calculate the rate of gain.

- why does RBP underestimate? as you increase the patience parameter, you go deeper down the results. however, as you go deeper, you obtain better performance, but at a diminishing rate. like the difference based strategies, rbp is statistically signficant from ss11. except for T2, where no differences exist. rolling a dice doesnt perform as well. says it has a good user model, but we are showing maybe it doesn't.

- pagination.

- combination strategies do well!
    - people consider how annoyed/satisfied they are. not a single criterion for judging when to stop.
    -

    \begin{table}[t!]
        \caption[GAIN]{GAIN}
        \label{tbl:conclusion_gain}
        \renewcommand{\arraystretch}{1.8}
        \begin{center}
        \begin{tabulary}{\textwidth}{L{0.4cm}@{\CS}L{2.8cm}@{\CS}D{2.6cm}@{\CS}D{2.6cm}@{\CS}D{2.6cm}@{\CS}D{2.6cm}@{\CS}}

            & & \lbluecell \textbf{Time/RS} & \lbluecell \textbf{Time/Doc.} & \lbluecell \textbf{CG} & \lbluecell \textbf{CG/Second} \\

            \RS \multirow{4}{*}{\rotatebox{90}{\hspace*{-4mm}\textbf{Chapter~\ref{chap:snippets}}}} & \lbluecell\textbf{T0} & \cell xx & \cell xx & \cell xx & \cell xx \\
            \RS & \lbluecell\textbf{T1} & \cell xx & \cell xx & \cell xx & \cell xx \\
            \RS & \lbluecell\textbf{T2} & \cell xx & \cell xx & \cell xx & \cell xx \\
            \RS & \lbluecell\textbf{T4} & \cell xx & \cell xx & \cell xx & \cell xx \\
        
            \RS\RS\RS \multirow{4}{*}{\rotatebox{90}{\hspace*{-4mm}\textbf{Chapter~\ref{chap:diversity}}}} & \lbluecell\textbf{D-AS} & \cell xx & \cell xx & \cell xx & \cell xx \\
            \RS & \lbluecell\textbf{ND-AS} & \cell xx & \cell xx & \cell xx & \cell xx \\
            \RS & \lbluecell\textbf{D-AD} & \cell xx & \cell xx & \cell xx & \cell xx \\
            \RS & \lbluecell\textbf{ND-AD} & \cell xx & \cell xx & \cell xx & \cell xx \\
        
        \end{tabulary}
        \end{center}
    \end{table}

\subsection{Simulations of Interaction}

- then move onto a discussion of our simulation findings.
- talk about the different issues that we raised.

- moving to combination approaches, like bejewled~\cite{zhang2017bejewled}, etc.

if a searcher performs badly/worse than always, they could be stopping queries early on that are bad, and entering those that are good, saving documents. likelihood that relevant documents already saved will reappear in subsequent queries later on, they have more time to issue more if they skip queries! and the judgement is such that if it's relevant, you go in. no consideration for things observed previously. did not consider this; so you enter a SERP, but there's nothing new to save even though it looked good! mismatch here -- something to address in future work.

- talk about the simulations
    - running the simulations. expensive. complicated.
    - as we introduced the SERP level stopping decision point, the complexity increased massively -- and so did the time required to run them.
    - talk about the pre-rolled judgements, too. methodological contribution. ensures repeatable, reproducible research.

- did we do enough runs?
    - we could justify why 50 DM runs was chosen.
    - but was this enough? may not be.
    - maybe we dont have enough trials.
    - and when we dont have enough trials to average over, the power of our experiments could be insufficient.
        - so we could be missing trends. we could be missing things that we simply cannot see.
        - limitation placed upon me by the hardware available to run the experiments. future work.
        - WE MENTION POWER IN SECTION~\ref{sec:methodology:user:flow} -- WITHIN-SUBJECTS INCREASES POWER. BUT WAS IT INCREASED ENOUGH?

would have been better to do it over 50 topics, rather than five.
previous papers show smoother curves.
we tried to compensate for this by doing 50 runs.
but probably not a good drop in solution.
why did we do this though? not enough data. needed to do things in a consistent way.


\section{Conclusion}\label{sec:conclusions:conclusion}

- what is the conclusion?
    - there is no overall winning combination. simple strategies seem to do better in terms of offering outright performance, and approximations. in terms of approximations, tuning a given stopping strategy will yield good approximations, regardless of the strategy you follow. evident with SS1-FIX for example, with comparatively deep depths (i.e. x1=24).

- we also see improvements in modelling.
- at the expense of increased complexity (in terms of running them), the simulations have been shown to be more realistic in terms of approximating click depths.
    - it does appear that taking scent into account is important. leads to slightly lower error rates, although we could not demonstrate this difference to be significant.

- limitations of the work could influence work, hide trends.
- nevertheless, it is an important contribution that demonstrates how task and interface affect stopping behaviour.

\section{Future Research Directions}\label{sec:conclusions:future}
From the summary and discussion of our empirical results, a number of potential avenues for future work can be considered. In this penultimate section, we consider these possibilities, presenting them across four main categories. These are: how to improve the realism of simulations of interaction further; the consideration of stopping heuristics and strategies; considering simulation trials and topics; and considering the modelling of stopping from the level of individual searchers.

\subsection{Improving Simulation Realism}\label{sec:conclusions:future:improving}
In this thesis, we presented the~\gls{acr:csm}, a high-level, conceptual searcher model. It encapsulates many of the different activities and decision points that searchers would contend with across informational search tasks. With the inclusion of the new~\gls{acr:serp} level stopping decision point, improvements were made to the realism of the simulations that were executed with the~\gls{acr:csm}. However, \emph{what changes could we subsequently make to the~\gls{acr:csm} and related infrastructure in future work that would aid in advancing the realism of these simulations further?} As illustrated below, we consider this open question from three main research strands.

\begin{figure}[h!]
    \centering
    \resizebox{1\hsize}{!}{
    \includegraphics[width=1\textwidth]{figures/ch10-future_simulations.pdf}}
\end{figure}

\blueboxheader{Contextual and Cognitive}
Our first strand considers \genericblack{contextual} and \genericblack{cognitive} factors. All experimentation in this thesis was conducted under the domain of news search, with subjects of the user studies asked to imagine that they were newspaper reporters, having being given a task to find documents that they thought were relevant to a particular topic. However, this scenario is very specific. If we performed studies with the same methodology, but under a different search context, would we find similar results? Arguably, behaviours will change -- general web search and a detailed examination of content under the context we employed will result in different outcomes. Different tasks can also be considered. Aspectual and ad-hoc tasks were considered as we believed they would offer the greatest difference in terms of stopping behaviours. Would other retrieval tasks offer even bigger differences in terms of searcher behaviours?

Other factors such as the location, device and other external pressures will also undoubtedly influence the outcome of the results obtained. Crowdsourced subjects whose behaviours are reported in this thesis conducted our experiments on a desktop or laptop computer. They were instructed to be in a comfortable, quiet location, free from major distractions. In reality however, individuals are less likely to search in such conditions. Perhaps time pressures would influence their behaviours -- a student under pressure to finish a draft of her paper will behave differently to one who is not. With the proliferation of mobile devices such as smartphones, searching on such devices must also be considered. A recent study by~\cite{ong2017scent_behaviour} demonstrated that search behaviours for example do differ between those using desktop computers and smartphones.

Much work remains on how we can understand and subsequently model the cognitive processes and factors that influence how individuals behave when searching. Individuals are unique; behaviours will undoubtedly differ from person to person. Within the modelling process, novel techniques can be applied that could possibly improve the realism of simulations. For example, within the \simiir~framework, the search context component tracks a list of queries issued, documents examined (and saved), along with other measures. Could this component be manipulated in such a way as to better mimic the behaviours of a human? Rather than maintaining a perfect list of everything that has been examined, a simulated searcher could be programmed to become `forgetful' in remembering what they have examined, with certain cues within a document reminding them that this is something that they may have previously examined.

\blueboxheader{Conceptual Modelling}
We next consider a number of further enhancements to the~\gls{acr:csm} that could improve the realism of simulations further. Examples in the illustration above consider four potential areas for future improvement. \genericblack{Tool switching}, as demonstrated by~\cite{thomas2014modelling_behaviour}, would be considered at the beginning of the search process. It would enable a searcher to determine what tool, or retrieval system, would be suited to help them satisfy their information need. This is opposed to the current~\gls{acr:csm} as presented in the thesis, that assumes a retrieval system has been selected \emph{a priori.} A study by~\cite{white2009tool_switching} has shown that predicting tool switching may be feasible. They reported that sufficiently consistent behaviours exhibited by searchers in relation to this phenomenon led to accurate predictions of tool switching events.

\genericblack{Results pagination} is also listed in the illustration above. Here, a simulated searcher will be presented with~\glsplural{acr:serp} that are split across a number of different pages, rather than examining a continuous ranked list of results. This would involve the notion of extracting additional grounding data from interaction logs, perhaps such as the likelihood of a searcher continuing to the next~\gls{acr:serp} page, given their interaction history. This would likely impact upon the realism of simulations, as a study by~\cite{jansen2005analysis} showed a sharp decrease in content examined after the first page of results.

Further examination of modelling stopping behaviours within the~\gls{acr:csm} is also considered; refer to Section~\ref{sec:conclusions:future:stopping} for further details.

\blueboxheader{Stochastic to Deterministic} Decisions as to the attractiveness of result summaries and the relevance of documents within our simulations of interaction are determined \emph{stochastically,} or by a roll of the dice. While a simplifying assumption that has been used in many other studies employing simulations of interaction, this is an unrealistic approach. If implemented correctly, a more \emph{deterministic} solution would offer more realistic simulations, where simulated searchers would be able to \emph{learn} as they traverse through content, improving their decision making abilities based upon the content observed, rather than the outcome of a die roll. Advancements in understanding the \emph{information triage} process would undoubtedly lead to improved realism. In addition, the inclusion of \emph{variable interaction costs} would also benefit simulations.\footnote{As discussed previously in this thesis, \emph{time-biased gain}~\citep{smucker2012tbg} is an example of such an approach.}

\subsection{Stopping Heuristics and Strategies}\label{sec:conclusions:future:stopping}
In this thesis, we considered a total of twelve different stopping strategies, operationalised from a total of eight different stopping heuristics (and the~\gls{acr:rbp}~\gls{acr:ir} evaluation measure). We showed how each of the different strategies perform over a number of different experimental interfaces and conditions. During the methodological design stage, it became apparent that the approaches taken for the operationalisation of the selected stopping strategies was just one of many. \emph{What if we implemented our stopping strategies in different ways? Why did we select these strategies?} Here, we consider these questions with insight into what might happen if they were to be explored further.

\blueboxbold{Stopping Decision Points}
Following on with the theme of improving the underlying~\gls{acr:csm}, additional stopping decision points could be included. These would provides searchers subscribing to the~\gls{acr:csm} with more flexibility regarding when they stop examining content. Additional stopping decision points could for example include one for tool switching. In this example, a searcher, after spending some period of time on one retrieval system, could decide to stop using it after some criteria are met. After this point has been reached, they will then switch to retrieval system. A further interesting research question would be whether the the result summary level stopping strategies trialled in this thesis would work at different stopping decision points. For example, at a session level, would these strategies make sense? Would using them at that decision point lead to a better matchup with real-world stopping behaviours?

\blueboxbold{Stopping Strategy Selection}
From here, we can also consider a further decision point that could be encoded within the~\gls{acr:csm}. Inspired from \blueboxbold{SS11-COMB}, consideration must be taken into deciding \emph{why} and \emph{when} a particular stopping strategy could be employed. As we demonstrated in Figure~\ref{fig:ss11_combo} on page~\pageref{fig:ss11_combo}, \blueboxbold{SS11-COMB} employs both the frustration and give-up time-based stopping heuristics -- but not at once. Rather, a decision is made pertaining to the quality of the presented~\gls{acr:serp} (much like the~\gls{acr:serp} level stopping decision point). The outcome of this decision then dictates what stopping strategy is employed for the remainder of the query. Further refinements to this approach could for example include additional stopping strategies and a wider range of conditions for employing them. Empirical evidence could be extracted from interaction logs to determine if, under certain circumstances, searchers would favour one approach over another.

\blueboxbold{Stopping Strategy Operationalisation}
An open question arising from the work in this thesis considers: \emph{how do you operationalise the stopping heuristics?} Clearly, from the outline of the twelve stopping strategies in Chapter~\ref{chap:strategies} on page~\pageref{chap:strategies} (and implementation methodology in Section~\ref{sec:method:simulation:grounding:stopping} on page~\pageref{sec:method:simulation:grounding:stopping}), there are a large number different ways in which the stopping strategies can be implemented. While we provided a means and justification for the approaches that we took in this thesis, we have reason to believe that some of the stopping strategies -- especially \blueboxbold{SS6-DT}, \blueboxbold{SS7-DKL} and \blueboxbold{SS8-IFT} performed poorly, perhaps because of our implementations. For example, the rate of gain for \blueboxbold{SS8-IFT} could have been computed on a per topic basis. Further work will be required in order to determine if different implementations would lead to performance improvements.

\blueboxbold{Considering Additional Stopping Heuristics}
Of course, the eight stopping heuristics that we considered in this thesis do not constitute the entirety of the heuristics defined in the literature. We selected these heuristics as they offered interesting differences between one another, were \emph{relatively} straightforward to implement, and would likely be discernible across complex informational search tasks. Unused heuristics such as the mental list stopping heuristic (considering different criteria that must be met, as outlined by~\cite{nickles1995judgment} and detailed in Section~\ref{sec:stopping_background:heuristics:mental} on page~\pageref{sec:stopping_background:heuristics:mental}) would have been much more challenging to operationalise and implement -- and even so, would such a heuristic be suitable for the task at hand? The ability for a searcher to create a series of bullet points about a topic would imply he or she has some sound idea of what they are looking for. The searcher's knowledge of a topic may be so limited that such a heuristic would be unsuitable. Linking back to contextual factors above, considering additional search contexts (perhaps with searchers of astute and limited knowledge of a topic) would be interesting to examine.

\blueboxbold{Towards Future~\gls{acr:ir} Measures}
Given the above, findings from this research provides motivation for further work considering the inclusion of stopping heuristics within the measures that are used within~\gls{acr:ir} research. For example, stopping strategy \blueboxbold{SS5-COMB} demonstrated good overall and performance considering a searcher's satisfaction and tolerance to non-relevant material. This too has been shown in the \emph{Bejeweled} framework~\citep{zhang2017bejewled}, leading to the development of an updated evaluation measure considering the costs and gains of searching~\citep{azzopardi2018cwl}.

\subsection{Simulation Trials and Topics}
We also consider future work in terms of \emph{how} the simulations of interaction could be run. While 50 trials were selected because of the fact that approximately 50 subjects partook in each user study, there may be trends and significant differences that we simply did not observe because of a lack of power. This limitation was also imposed with an insufficient amount of processing power to complete the experiments in a reasonable timeframe. With more powerful computer hardware, scaling up the experiments with more trials would have become a more realistic prospect.

We also consider using five topics for our performance \emph{(what-if)} experiments to be a limiting factor. While the decision to use five topics was justified due to a lack of data (considering entities across the remaining 45 topics in Chapter~\ref{chap:diversity}) -- and to ensure that comparisons between interfaces and conditions were fair -- 50 topics would have been preferred. If data were available for the remaining 45 topics, we could then trial additional performance runs, which may also lead to the observation of other trends and potential significant differences.

\subsection{Individual Searcher Stopping Behaviours}
Our final consideration for future work revolves around the notion of \emph{individual searcher stopping behaviours.} In this thesis, we considered searcher stopping behaviours, reported across \~50 subjects, over each interface and condition that was trialled. This provided us with a rough approximation as to what strategies work best, with similar findings reported across interfaces and conditions. However, research has shown that individual searcher behaviours are different. If we considered individual searchers, what trends would we then observe? Could we for example perform a classification of searcher stopping behaviours, such that we could produce a classification of stopping behaviours? For example, such an approach was followed by~\cite{smucker2011user_strategies}, who devised a classification of searchers when examining documents -- with \emph{fast and liberal} or \emph{slow and neutral} classifications.

\section{Final Remarks}\label{sec:conclusions:remarks}
Modelling search is complex, with searchers able to perform a wide range of actions and make a number of different decisions. We have shown in this thesis that stopping behaviours are also difficult to examine and measure. Nevertheless, we motivate the fact that we need to consider stopping behaviours in the development of future evaluation measures and search interfaces, with this work suggesting what strategies will perform well.

Despite the inherently difficult task that understanding and modelling stopping behaviours represents, we believe that the potential benefits of further exploration in this area will undoubtedly aid the searchers and researchers of future retrieval systems. Now that this is all done, \emph{I} am off to the pub -- and having reached the end of this thesis, you should go, too!